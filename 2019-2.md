```cpp
2月18号
1.完成一篇论文笔记和阅读一篇论文
2.测试了MyNet的Xunit版本和L2 loss版本。
3.完成MyNet 数据增强代码以及增强后使用密集VGG层做loss的代码
4.撰写最新AI新得
5.在代码里添加测试全部validation的代码，正在进行中.......

2月19日
1.继续修改代码，修改失败，gg
2.看完昨天没看完的那半篇论文。

2月20日
1.采用B方案，自动测试全部的模型，完成代码并实现测试，成功！
2.写半篇技术博客。
3.看一篇论文
4.完成只使用L2 loss的训练和测试，以及数据增强代码以及增强后使用密集VGG层做loss的模型测试
5.使用减少参数量的EDSR进行训练。

2月21日
1.完成pytorch squid架构代码在本机上的debug工作，在本机上训练和测试调整后初步结果正常，已上传到服务器，待继续调试。
2.测试加入attention的Unet。
3.将MyNet里的卷积替换为denseblock里镶嵌resblock，提交并训练。

2月22日
1.完成pytorch框架代码在服务器上的调试，开始训练。
2.测试EDSR的结果
3.完成论文笔记一篇。
4.测试pytorch版本的结果

2月25日
1.完成DPED(L2)的训练和测试，以及0225-MyNet-resblock(残差0.1)，0225-MyNet-resblock+channel attention(残差0.1)
0225-MyNet-pytorch，0225-MyNet-denseblock（2 layers)的训练和测试。
2.阅读一篇论文。

2月26日
1.完成八组实验的训练和测试
2.阅读一篇论文，完成论文笔记一份
3.修改pytorch代码，增加VGG loss
```
